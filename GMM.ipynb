{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.mixture import GaussianMixture\n",
    "from tqdm.notebook import tqdm\n",
    "import os\n",
    "import numpy as np\n",
    "import glob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "decode = lambda file_id: {\n",
    "    'user_id': int(file_id[:3]),\n",
    "    'session_no': int(file_id[3]),\n",
    "    'keyboard_code': int(file_id[4]),\n",
    "    'task_no': int(file_id[5]),\n",
    "}\n",
    "\n",
    "class Digraph:\n",
    "    x = 0\n",
    "    y = 1\n",
    "    h1 = 2\n",
    "    h2 = 3\n",
    "    pp = 4\n",
    "    rp = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "af014b07c1844cf18689f9051983c251",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading digraphs:   0%|          | 0/149 [00:00<?, ?user/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4d9b47c5cc4f420a9caa5d71878d2ff7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Splitting digraphs:   0%|          | 0/149 [00:00<?, ?user/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "TRAIN, VAL, TEST = 0.75, 0.15, 0.10\n",
    "try:\n",
    "    split_user_digraphs = np.load('digraphs.npz', allow_pickle=True)[()]\n",
    "    print('Loaded split digraphs from file')\n",
    "except FileNotFoundError:\n",
    "    user_digraphs = {}\n",
    "    combined_files = glob.glob('digraphs/*/*/*.txt')\n",
    "    users = max(decode(os.path.basename(filename))['user_id'] for filename in combined_files) + 1\n",
    "    for user in tqdm(range(users), total=users, desc='Loading digraphs', unit='user'):\n",
    "        files = [filename for filename in combined_files if decode(os.path.basename(filename))['user_id'] == user]\n",
    "        user_digraphs[user] = {}\n",
    "        for filename in files:\n",
    "            with open(filename) as file:\n",
    "                lines = file.readlines()\n",
    "                for line in lines:\n",
    "                    key1, key2, x, y, h1, h2, pp, rp = line.split()\n",
    "                    digraph = [int(x), int(y), int(h1), int(h2), int(pp), int(rp)]\n",
    "                    if (key1, key2) not in user_digraphs[user]:\n",
    "                        user_digraphs[user][(key1, key2)] = []\n",
    "                    user_digraphs[user][(key1, key2)].append(digraph)\n",
    "\n",
    "    split_user_digraphs = {\n",
    "        'train': {},\n",
    "        'val': {},\n",
    "        'test': {},\n",
    "        'splits': {\n",
    "            'train': TRAIN,\n",
    "            'val': VAL,\n",
    "            'test': TEST,\n",
    "        }\n",
    "    }\n",
    "    for user in tqdm(range(users), total=users, desc='Splitting digraphs', unit='user'):\n",
    "        for key_pair in user_digraphs[user]:\n",
    "            user_digraphs[user][key_pair] = np.array(user_digraphs[user][key_pair])\n",
    "            try:\n",
    "                train, val_test = train_test_split(user_digraphs[user][key_pair], train_size=TRAIN, test_size=VAL+TEST, shuffle=True)\n",
    "                val, test = train_test_split(val_test, train_size=VAL/(VAL+TEST), test_size=TEST/(VAL+TEST), shuffle=True)\n",
    "                if user not in split_user_digraphs['train']:\n",
    "                    split_user_digraphs['train'][user] = {}\n",
    "                    split_user_digraphs['val'][user] = {}\n",
    "                    split_user_digraphs['test'][user] = {}\n",
    "                split_user_digraphs['train'][user][key_pair] = train\n",
    "                split_user_digraphs['val'][user][key_pair] = val\n",
    "                split_user_digraphs['test'][user][key_pair] = test\n",
    "            except ValueError:\n",
    "                # Not enough data to split\n",
    "                pass\n",
    "    np.save('digraphs.npy', split_user_digraphs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f2ee94577522494394565d9e08f68157",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Fitting models:   0%|          | 0/148 [00:00<?, ?user/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "MIN_SAMPLES = 50\n",
    "N_COMPONENTS = 2\n",
    "try:\n",
    "    user_models = np.load('user_models_pp.npy', allow_pickle=True)[()]\n",
    "    print('Loaded models from file')\n",
    "except FileNotFoundError:\n",
    "    user_models = {}\n",
    "    for user in tqdm(split_user_digraphs['train'], desc='Fitting models', unit='user'):\n",
    "        user_models[user] = {}\n",
    "        for (key_pair, digraphs) in split_user_digraphs['train'][user].items():\n",
    "            if len(digraphs) < MIN_SAMPLES:\n",
    "                continue\n",
    "            model = GaussianMixture(n_components=N_COMPONENTS)\n",
    "            # model.fit(user_digraphs[user][digraph][:, [Digraph.h1, Digraph.h2, Digraph.pp, Digraph.rp]])\n",
    "            model.fit(digraphs[:, [Digraph.pp]])\n",
    "            user_models[user][key_pair] = model\n",
    "    np.save('user_models_pp.npy', user_models)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def similarity_score(user_digraphs, profile_model, z_threshold=1):\n",
    "    passed_digraphs = 0\n",
    "    total_digraphs = 0\n",
    "    for (key_pair, digraphs) in user_digraphs.items():\n",
    "        if key_pair not in profile_model:\n",
    "            continue\n",
    "        model = profile_model[key_pair]\n",
    "        for digraph in digraphs:\n",
    "            total_digraphs += 1\n",
    "            for i in range(model.n_components):\n",
    "                weight, mean, covariance = model.weights_[i], model.means_[i], model.covariances_[i]\n",
    "                z_score = (digraph[Digraph.pp] - mean) / np.sqrt(covariance)\n",
    "                if abs(z_score) <= z_threshold:\n",
    "                    passed_digraphs += weight\n",
    "                    break\n",
    "    return passed_digraphs / total_digraphs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def classify(user_digraphs, profile_model, pass_threshold=0.60):\n",
    "    score = similarity_score(user_digraphs, profile_model)\n",
    "    return score >= pass_threshold, score-pass_threshold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7fb0434d6c634cc0b54d2e20bce5beac",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing users against selves:   0%|          | 0/148 [00:00<?, ?user/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FRR = 25.676%\n",
      "Average error confidence = 2.545%\n",
      "Average correct confidence = 3.643%\n",
      "Average confidence = 3.361%\n"
     ]
    }
   ],
   "source": [
    "errors = 0\n",
    "net_error_confidence = 0\n",
    "net_correct_confidence = 0\n",
    "total = 0\n",
    "for user in tqdm(split_user_digraphs['test'], desc='Testing users against selves', unit='user'):\n",
    "    profile_model = user_models[user]\n",
    "    same_user, distance_from_threshold = classify(split_user_digraphs['test'][user], profile_model)\n",
    "    if same_user == False:\n",
    "        errors += 1\n",
    "        net_error_confidence += abs(distance_from_threshold)\n",
    "    else:\n",
    "        net_correct_confidence += abs(distance_from_threshold)\n",
    "    total += 1\n",
    "print(f\"FRR = {errors*100/total:2.3f}%\")\n",
    "print(f\"Average error confidence = {net_error_confidence*100/errors:2.3f}%\")\n",
    "print(f\"Average correct confidence = {net_correct_confidence*100/(total-errors):2.3f}%\")\n",
    "print(f\"Average confidence = {(net_error_confidence+net_correct_confidence)*100/total:2.3f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "84b16cca0d1f4521af580b7772413383",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing users against others:   0%|          | 0/148 [00:00<?, ?user/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FAR = 4.739%\n",
      "Average error confidence = 2.596%\n",
      "Average correct confidence = 12.162%\n",
      "Average confidence = 11.709%\n"
     ]
    }
   ],
   "source": [
    "errors = 0\n",
    "net_error_confidence = 0\n",
    "net_correct_confidence = 0\n",
    "total = 0\n",
    "for user in tqdm(split_user_digraphs['test'], desc='Testing users against others', unit='user'):\n",
    "    profile_model = user_models[user]\n",
    "    for other_user in split_user_digraphs['test']:\n",
    "        if other_user == user:\n",
    "            continue\n",
    "        same_user, distance_from_threshold = classify(split_user_digraphs['test'][other_user], profile_model)\n",
    "        if same_user == True:\n",
    "            errors += 1\n",
    "            net_error_confidence += abs(distance_from_threshold)\n",
    "        else:\n",
    "            net_correct_confidence += abs(distance_from_threshold)\n",
    "        total += 1\n",
    "print(f\"FAR = {errors*100/total:2.3f}%\")\n",
    "print(f\"Average error confidence = {net_error_confidence*100/errors:2.3f}%\")\n",
    "print(f\"Average correct confidence = {net_correct_confidence*100/(total-errors):2.3f}%\")\n",
    "print(f\"Average confidence = {(net_error_confidence+net_correct_confidence)*100/total:2.3f}%\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
